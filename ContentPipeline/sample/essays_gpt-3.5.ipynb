{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from json_repair import repair_json\n",
    "import pandas as pd\n",
    "from prutils.prevaluation import PrEvaluation\n",
    "\n",
    "dataset = load_dataset(\"jingjietan/essays-big5\", cache_dir=\"../datasets\")\n",
    "\n",
    "name = \"essays_gpt-3.5-turbo-0125\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_sample_json(id,user_text):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"Analyze the user's personality using the Big 5 framework based on the given text.\\n\"\n",
    "                \"Output the result in this JSON format:\\n\"\n",
    "                \"{\\n\"\n",
    "                \"  'dimensions': {\\n\"\n",
    "                \"    'Openness': {'evidence': '', 'label': '0/1'},\\n\"\n",
    "                \"    'Conscientiousness': {'evidence': '', 'label': '0/1'},\\n\"\n",
    "                \"    'Extraversion': {'evidence': '', 'label': '0/1'},\\n\"\n",
    "                \"    'Agreeableness': {'evidence': '', 'label': '0/1'},\\n\"\n",
    "                \"    'Neuroticism': {'evidence': '', 'label': '0/1'}\\n\"\n",
    "                \"  }\\n\"\n",
    "                \"}\\n\\n\"\n",
    "                \"For each dimension, provide:\\n\"\n",
    "                \"- evidence: Analysis of the text reflecting the trait. Give examples (content and/or tone) from the user's message. Avoid using punctuation\\n\"\n",
    "                \"- label: Provide only a value (0 for low; or 1 for high) to indicate the traits.\\n\\n\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_text\n",
    "        }\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "    data = {\n",
    "        \"custom_id\": str(id),\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-3.5-turbo-0125\",\n",
    "            \"messages\": messages,\n",
    "            \"response_format\": { \"type\": \"json_object\" },\n",
    "            \"max_tokens\": 500,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = dataset['test']\n",
    "testset = pd.DataFrame(testset)\n",
    "\n",
    "# create .jsonl file\n",
    "with open(name + '.jsonl', 'w') as f:\n",
    "    for _, row in testset.iterrows():\n",
    "        data = get_single_sample_json(row['__index_level_0__'], row['text'])\n",
    "        f.write(json.dumps(data))\n",
    "        f.write('\\n')\n",
    "print(len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit batch to open ai using jsonl file\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    api_key=\"___\"\n",
    ")\n",
    "\n",
    "input_file = client.files.create(\n",
    "  file=open(name+\".jsonl\", \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")\n",
    "\n",
    "print(input_file.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = client.batches.create(\n",
    "    input_file_id=input_file.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"nightly eval job\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = client.batches.retrieve(batch.id)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_response = client.files.content(batch.output_file_id)\n",
    "#print(file_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"id\",\"o_evi\", \"o_type\", \"c_evi\", \"c_type\", \"e_evi\", \"e_type\", \"a_evi\", \"a_type\", \"n_evi\", \"n_type\", \"O\", \"C\", \"E\", \"A\", \"N\"])\n",
    "\n",
    "for line in file_response.text.strip().split('\\n'):\n",
    "    line = json.loads(line)\n",
    "    custom_id = line[\"custom_id\"]\n",
    "    content = line[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    O = testset[testset[\"__index_level_0__\"] == int(custom_id)][\"O\"].values[0]\n",
    "    C = testset[testset[\"__index_level_0__\"] == int(custom_id)][\"C\"].values[0]\n",
    "    E = testset[testset[\"__index_level_0__\"] == int(custom_id)][\"E\"].values[0]\n",
    "    A = testset[testset[\"__index_level_0__\"] == int(custom_id)][\"A\"].values[0]\n",
    "    N = testset[testset[\"__index_level_0__\"] == int(custom_id)][\"N\"].values[0]\n",
    "\n",
    "    try:\n",
    "        content = repair_json(content)\n",
    "        content = json.loads(content)\n",
    "        content = content[\"dimensions\"]\n",
    "\n",
    "        o_evi = content[\"Openness\"][\"evidence\"]\n",
    "        o_type = content[\"Openness\"][\"label\"]\n",
    "        c_evi = content[\"Conscientiousness\"][\"evidence\"]\n",
    "        c_type = content[\"Conscientiousness\"][\"label\"]\n",
    "        e_evi = content[\"Extraversion\"][\"evidence\"]\n",
    "        e_type = content[\"Extraversion\"][\"label\"]\n",
    "        a_evi = content[\"Agreeableness\"][\"evidence\"]\n",
    "        a_type = content[\"Agreeableness\"][\"label\"]\n",
    "        n_evi = content[\"Neuroticism\"][\"evidence\"]\n",
    "        n_type = content[\"Neuroticism\"][\"label\"]\n",
    "\n",
    "        #make to pandas\n",
    "        df = df.append({\"id\":custom_id, \"o_evi\": o_evi, \"o_type\": o_type, \"c_evi\": c_evi, \"c_type\": c_type, \"e_evi\": e_evi, \"e_type\": e_type, \"a_evi\": a_evi, \"a_type\": a_type, \"n_evi\": n_evi, \"n_type\": n_type, \"O\":O, \"C\":C, \"E\":E, \"A\":A, \"N\":N}, ignore_index=True)\n",
    "    except:\n",
    "        #df = df.append({\"id\":custom_id,\"e_i_evi\": \"\", \"e_i_type\": \"\", \"s_n_evi\": \"\", \"s_n_type\": \"\", \"t_f_evi\": \"\", \"t_f_type\": \"\", \"j_p_evi\": \"\", \"j_p_type\": \"\", \"O\":O, \"C\":C, \"E\":E, \"A\":A}, ignore_index=True)\n",
    "        # append the content to a txt file\n",
    "        with open(name + '_error.txt', 'a') as f:\n",
    "            f.write(str(content))\n",
    "            f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"o_type\"] = df[\"o_type\"].apply(lambda x: 1 if str(x) == \"1\" else 0 if str(x).upper() == \"0\" else -1).astype(int)\n",
    "df[\"c_type\"] = df[\"c_type\"].apply(lambda x: 1 if str(x) == \"1\" else 0 if str(x).upper() == \"0\" else -1).astype(int)\n",
    "df[\"e_type\"] = df[\"e_type\"].apply(lambda x: 1 if str(x) == \"1\" else 0 if str(x).upper() == \"0\" else -1).astype(int) \n",
    "df[\"a_type\"] = df[\"a_type\"].apply(lambda x: 1 if str(x) == \"1\" else 0 if str(x).upper() == \"0\" else -1).astype(int)\n",
    "df[\"n_type\"] = df[\"n_type\"].apply(lambda x: 1 if str(x) == \"1\" else 0 if str(x).upper() == \"0\" else -1).astype(int)\n",
    "\n",
    "#make int\n",
    "df[\"o_type\"] = df[\"o_type\"].astype(int)\n",
    "df[\"c_type\"] = df[\"c_type\"].astype(int)\n",
    "df[\"e_type\"] = df[\"e_type\"].astype(int)\n",
    "df[\"a_type\"] = df[\"a_type\"].astype(int)\n",
    "df[\"n_type\"] = df[\"n_type\"].astype(int)\n",
    "\n",
    "df[\"O\"] = df[\"O\"].astype(int)\n",
    "df[\"C\"] = df[\"C\"].astype(int)\n",
    "df[\"E\"] = df[\"E\"].astype(int)\n",
    "df[\"A\"] = df[\"A\"].astype(int)\n",
    "df[\"N\"] = df[\"N\"].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df.to_csv(name + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #read from csv\n",
    "# import pandas as pd\n",
    "# df = pd.read_csv(name + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = PrEvaluation(\"O\")\n",
    "O.push([df[\"o_type\"].to_list()],[df[\"O\"].to_list()])\n",
    "O.print_performance()\n",
    "\n",
    "C = PrEvaluation(\"C\")\n",
    "C.push([df[\"c_type\"].to_list()],[df[\"C\"].to_list()])\n",
    "C.print_performance()\n",
    "\n",
    "E = PrEvaluation(\"E\")\n",
    "E.push([df[\"e_type\"].to_list()],[df[\"E\"].to_list()])\n",
    "E.print_performance()\n",
    "\n",
    "A = PrEvaluation(\"A\")\n",
    "A.push([df[\"a_type\"].to_list()],[df[\"A\"].to_list()])\n",
    "A.print_performance()\n",
    "\n",
    "N = PrEvaluation(\"N\")\n",
    "N.push([df[\"n_type\"].to_list()],[df[\"N\"].to_list()])\n",
    "N.print_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chekc unique df[\"N\"].to_list()\n",
    "print(df[\"n_type\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phdwork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
